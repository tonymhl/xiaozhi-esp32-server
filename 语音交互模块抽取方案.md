# å°æ™ºESP32è¯­éŸ³äº¤äº’æ¨¡å—æŠ½å–æ–¹æ¡ˆä¸æŠ€æœ¯æ–‡æ¡£

## ğŸ“‹ ç›®å½•
1. [é¡¹ç›®ç°çŠ¶åˆ†æ](#é¡¹ç›®ç°çŠ¶åˆ†æ)
2. [è¯­éŸ³äº¤äº’æ¶æ„åˆ†æ](#è¯­éŸ³äº¤äº’æ¶æ„åˆ†æ)
3. [æ ¸å¿ƒæ¨¡å—åŠŸèƒ½æ‹†è§£](#æ ¸å¿ƒæ¨¡å—åŠŸèƒ½æ‹†è§£)
4. [æœ€å°åŠŸèƒ½é›†æŠ½å–æ–¹æ¡ˆ](#æœ€å°åŠŸèƒ½é›†æŠ½å–æ–¹æ¡ˆ)
5. [ç‹¬ç«‹éƒ¨ç½²æ¶æ„è®¾è®¡](#ç‹¬ç«‹éƒ¨ç½²æ¶æ„è®¾è®¡)
6. [æŠ€æœ¯å®ç°è·¯çº¿](#æŠ€æœ¯å®ç°è·¯çº¿)
7. [è¿ç§»éƒ¨ç½²æŒ‡å—](#è¿ç§»éƒ¨ç½²æŒ‡å—)
8. [å»ºè®®ä¸é£é™©è¯„ä¼°](#å»ºè®®ä¸é£é™©è¯„ä¼°)

---

## 1. é¡¹ç›®ç°çŠ¶åˆ†æ

### 1.1 é¡¹ç›®æ•´ä½“æ¶æ„

**xiaozhi-esp32-server** æ˜¯ä¸€ä¸ªä¸ºESP32æ™ºèƒ½ç¡¬ä»¶æä¾›åç«¯æœåŠ¡çš„å®Œæ•´è§£å†³æ–¹æ¡ˆï¼ŒåŒ…å«ï¼š

```
é¡¹ç›®ç»“æ„:
â”œâ”€â”€ main/manager-api/          # Javaåç«¯ - æ™ºæ§å°ç®¡ç†æ¥å£
â”œâ”€â”€ main/manager-web/          # Vueå‰ç«¯ - Webç®¡ç†ç•Œé¢
â”œâ”€â”€ main/manager-mobile/       # ç§»åŠ¨ç«¯ç®¡ç†ç•Œé¢
â””â”€â”€ main/xiaozhi-server/       # Pythonåç«¯ - æ ¸å¿ƒè¯­éŸ³äº¤äº’æœåŠ¡
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ websocket_server.py    # WebSocketæœåŠ¡å™¨
    â”‚   â”œâ”€â”€ connection.py          # è¿æ¥å¤„ç†å™¨
    â”‚   â”œâ”€â”€ providers/             # å„ç±»æœåŠ¡æä¾›è€…
    â”‚   â”‚   â”œâ”€â”€ asr/              # è¯­éŸ³è¯†åˆ«
    â”‚   â”‚   â”œâ”€â”€ tts/              # è¯­éŸ³åˆæˆ
    â”‚   â”‚   â”œâ”€â”€ llm/              # å¤§è¯­è¨€æ¨¡å‹
    â”‚   â”‚   â”œâ”€â”€ vad/              # è¯­éŸ³æ´»åŠ¨æ£€æµ‹
    â”‚   â”‚   â”œâ”€â”€ vllm/             # è§†è§‰æ¨¡å‹
    â”‚   â”‚   â”œâ”€â”€ intent/           # æ„å›¾è¯†åˆ«
    â”‚   â”‚   â””â”€â”€ memory/           # è®°å¿†ç®¡ç†
    â”‚   â”œâ”€â”€ handle/               # æ¶ˆæ¯å¤„ç†å™¨
    â”‚   â””â”€â”€ utils/                # å·¥å…·ç±»
    â”œâ”€â”€ config/                   # é…ç½®ç®¡ç†
    â””â”€â”€ plugins_func/             # æ’ä»¶ç³»ç»Ÿ
```

### 1.2 æ ¸å¿ƒæŠ€æœ¯æ ˆ

**Pythonåç«¯æ ¸å¿ƒä¾èµ–:**
- `websockets` - WebSocketé€šä¿¡
- `asyncio` - å¼‚æ­¥å¤„ç†
- `funasr` - æœ¬åœ°è¯­éŸ³è¯†åˆ«
- `silero_vad` - è¯­éŸ³æ´»åŠ¨æ£€æµ‹
- `torch` - æ·±åº¦å­¦ä¹ æ¡†æ¶
- `openai` - OpenAIæ¥å£è°ƒç”¨
- `edge_tts` - å¾®è½¯TTS
- `opuslib_next` - OpuséŸ³é¢‘ç¼–è§£ç 

---

## 2. è¯­éŸ³äº¤äº’æ¶æ„åˆ†æ

### 2.1 å®Œæ•´äº¤äº’æµç¨‹

```mermaid
graph LR
    A[å®¢æˆ·ç«¯éŸ³é¢‘è¾“å…¥] --> B[WebSocketæ¥æ”¶]
    B --> C[VADè¯­éŸ³æ£€æµ‹]
    C --> D{æœ‰äººå£°?}
    D -->|æ˜¯| E[éŸ³é¢‘ç¼“å­˜]
    D -->|å¦| F[ä¸¢å¼ƒ]
    E --> G[ASRè¯­éŸ³è¯†åˆ«]
    G --> H[æ„å›¾è¯†åˆ«]
    H --> I[LLMç”Ÿæˆå›å¤]
    I --> J[TTSè¯­éŸ³åˆæˆ]
    J --> K[WebSocketè¿”å›]
    K --> L[å®¢æˆ·ç«¯æ’­æ”¾]
```

### 2.2 æ ¸å¿ƒæ¨¡å—èŒè´£

| æ¨¡å— | åŠŸèƒ½ | æŠ€æœ¯é€‰å‹ | æ˜¯å¦å¿…éœ€ |
|------|------|----------|----------|
| **VAD** | è¯­éŸ³æ´»åŠ¨æ£€æµ‹ | SileroVAD | âœ… æ ¸å¿ƒ |
| **ASR** | è¯­éŸ³è½¬æ–‡å­— | FunASR/é˜¿é‡Œäº‘/ç«å±±ç­‰ | âœ… æ ¸å¿ƒ |
| **LLM** | å¤§è¯­è¨€æ¨¡å‹ | OpenAIæ¥å£/æœ¬åœ°éƒ¨ç½² | âœ… æ ¸å¿ƒ |
| **Intent** | æ„å›¾è¯†åˆ« | function_call/LLM | âš ï¸ å¯é€‰ |
| **TTS** | æ–‡å­—è½¬è¯­éŸ³ | EdgeTTS/ç«å±±/é˜¿é‡Œäº‘ç­‰ | âœ… æ ¸å¿ƒ |
| **Memory** | å¯¹è¯è®°å¿† | æœ¬åœ°/mem0ai | âš ï¸ å¯é€‰ |
| **Tools** | å·¥å…·è°ƒç”¨ | MCP/IOT | âŒ éå¿…éœ€ |

---

## 3. æ ¸å¿ƒæ¨¡å—åŠŸèƒ½æ‹†è§£

### 3.1 WebSocketæœåŠ¡å™¨ (`websocket_server.py`)

**æ ¸å¿ƒåŠŸèƒ½:**
- ç®¡ç†WebSocketè¿æ¥
- åˆå§‹åŒ–VAD/ASR/LLM/TTSæ¨¡å—
- ä¸ºæ¯ä¸ªè¿æ¥åˆ›å»ºç‹¬ç«‹çš„`ConnectionHandler`

**å…³é”®ä»£ç ç»“æ„:**
```python
class WebSocketServer:
    def __init__(self, config):
        self.config = config
        # åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å—
        modules = initialize_modules(
            vad=True, asr=True, llm=True, ...
        )
        
    async def _handle_connection(self, websocket):
        handler = ConnectionHandler(
            config, vad, asr, llm, memory, intent
        )
        await handler.handle_connection(websocket)
```

### 3.2 è¿æ¥å¤„ç†å™¨ (`connection.py`)

**æ ¸å¿ƒèŒè´£:**
- ç®¡ç†å•ä¸ªè¿æ¥çš„ç”Ÿå‘½å‘¨æœŸ
- å¤„ç†éŸ³é¢‘æµæ¥æ”¶å’Œå‘é€
- åè°ƒå„æ¨¡å—çš„è°ƒç”¨
- ç»´æŠ¤å¯¹è¯ä¸Šä¸‹æ–‡

**å…³é”®å±æ€§:**
```python
class ConnectionHandler:
    # éŸ³é¢‘å¤„ç†
    self.asr_audio = []              # ASRéŸ³é¢‘ç¼“å­˜
    self.client_audio_buffer = []    # å®¢æˆ·ç«¯éŸ³é¢‘ç¼“å†²
    
    # çŠ¶æ€ç®¡ç†
    self.client_is_speaking = False  # å®¢æˆ·ç«¯æ˜¯å¦åœ¨è¯´è¯
    self.client_have_voice = False   # æ˜¯å¦æ£€æµ‹åˆ°è¯­éŸ³
    
    # å¯¹è¯ç®¡ç†
    self.dialogue = Dialogue()       # å¯¹è¯å†å²
    self.llm_finish_task = True      # LLMä»»åŠ¡å®Œæˆæ ‡å¿—
    
    # æ ¸å¿ƒæ¨¡å—å¼•ç”¨
    self.vad, self.asr, self.tts, self.llm
```

### 3.3 ASRæ¨¡å— (`core/providers/asr/`)

**æ¥å£è®¾è®¡:**
```python
class ASRProviderBase(ABC):
    @abstractmethod
    async def transcribe(self, audio_data: bytes) -> str:
        """è¯­éŸ³è¯†åˆ«æ¥å£"""
        pass
    
    async def handle_voice_stop(self, conn, audio_chunks):
        """å¤„ç†è¯­éŸ³åœæ­¢äº‹ä»¶"""
        # 1. éŸ³é¢‘æ ¼å¼è½¬æ¢
        # 2. è°ƒç”¨ASRå¼•æ“
        # 3. è¿”å›è¯†åˆ«æ–‡æœ¬
```

**æ”¯æŒçš„ASRç±»å‹:**
- `fun_local` - FunASRæœ¬åœ°è¯†åˆ« (æ¨è)
- `doubao_stream` - ç«å±±å¼•æ“æµå¼ASR
- `aliyun_stream` - é˜¿é‡Œäº‘æµå¼ASR
- `openai` - OpenAI Whisper API

### 3.4 TTSæ¨¡å— (`core/providers/tts/`)

**æ¥å£è®¾è®¡:**
```python
class TTSProviderBase:
    def to_tts(self, text: str) -> List[bytes]:
        """æ–‡å­—è½¬è¯­éŸ³"""
        # è¿”å›Opusç¼–ç çš„éŸ³é¢‘æ•°æ®
        pass
        
    def to_tts_stream(self, text: str):
        """æµå¼TTS (æ”¯æŒçš„æœåŠ¡)"""
        # ç”Ÿæˆå™¨æ¨¡å¼è¿”å›éŸ³é¢‘æµ
        for audio_chunk in audio_stream:
            yield audio_chunk
```

**æ”¯æŒçš„TTSç±»å‹:**
- `edge` - EdgeTTS (å…è´¹æ¨è)
- `linkerai` - çµçŠ€æµå¼TTS (å…è´¹)
- `doubao` - ç«å±±å¼•æ“TTS
- `aliyun_stream` - é˜¿é‡Œäº‘æµå¼TTS

---

## 4. æœ€å°åŠŸèƒ½é›†æŠ½å–æ–¹æ¡ˆ

### 4.1 æ–¹æ¡ˆA: è½»é‡çº§ç‹¬ç«‹æ¨¡å— â­æ¨è

**é€‚ç”¨åœºæ™¯:** åœ¨ç°æœ‰åç«¯ä¸­æ·»åŠ è¯­éŸ³äº¤äº’èƒ½åŠ›ï¼Œä¸ä¾èµ–å°æ™ºçš„å®Œæ•´ç”Ÿæ€

**æŠ½å–å†…å®¹:**

```
minimal-voice-module/
â”œâ”€â”€ voice_server.py           # ç®€åŒ–çš„WebSocketæœåŠ¡å™¨
â”œâ”€â”€ voice_handler.py          # è¯­éŸ³å¤„ç†æ ¸å¿ƒé€»è¾‘
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ asr/
â”‚   â”‚   â”œâ”€â”€ base.py          # ASRåŸºç±»
â”‚   â”‚   â”œâ”€â”€ fun_local.py     # FunASRæœ¬åœ°
â”‚   â”‚   â””â”€â”€ doubao_stream.py # æµå¼ASR (å¯é€‰)
â”‚   â”œâ”€â”€ tts/
â”‚   â”‚   â”œâ”€â”€ base.py          # TTSåŸºç±»
â”‚   â”‚   â”œâ”€â”€ edge.py          # EdgeTTS (å…è´¹)
â”‚   â”‚   â””â”€â”€ linkerai.py      # çµçŠ€TTS (å…è´¹)
â”‚   â””â”€â”€ vad/
â”‚       â””â”€â”€ silero.py        # SileroVAD
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ audio_utils.py       # éŸ³é¢‘å¤„ç†å·¥å…·
â”‚   â””â”€â”€ opus_encoder.py      # Opusç¼–è§£ç 
â”œâ”€â”€ config.yaml              # é…ç½®æ–‡ä»¶
â””â”€â”€ requirements.txt         # ä¾èµ–åˆ—è¡¨

æ ¸å¿ƒä¾èµ– (æœ€å°åŒ–):
- websockets
- funasr (å¦‚ä½¿ç”¨æœ¬åœ°ASR)
- silero_vad
- opuslib_next
- edge_tts (å¦‚ä½¿ç”¨EdgeTTS)
- httpx/aiohttp
```

**æ ¸å¿ƒæµç¨‹ç®€åŒ–:**

```python
# voice_handler.py
class VoiceHandler:
    def __init__(self, asr, tts, vad):
        self.asr = asr
        self.tts = tts
        self.vad = vad
        self.audio_buffer = []
        
    async def process_audio(self, audio_chunk):
        """å¤„ç†éŸ³é¢‘è¾“å…¥"""
        # 1. VADæ£€æµ‹
        is_speech = self.vad.detect(audio_chunk)
        
        if is_speech:
            self.audio_buffer.append(audio_chunk)
        elif self.audio_buffer:
            # 2. ASRè¯†åˆ«
            text = await self.asr.transcribe(self.audio_buffer)
            self.audio_buffer.clear()
            
            # 3. è¿”å›è¯†åˆ«ç»“æœ (ä¾›å¤–éƒ¨è°ƒç”¨API)
            return text
            
    async def text_to_speech(self, text):
        """æ–‡å­—è½¬è¯­éŸ³"""
        # è°ƒç”¨TTSç”ŸæˆéŸ³é¢‘
        audio_data = self.tts.to_tts(text)
        return audio_data
```

**ä¼˜åŠ¿:**
- âœ… ä»£ç é‡å° (~2000è¡Œ)
- âœ… ä¾èµ–å°‘ï¼Œæ˜“éƒ¨ç½²
- âœ… å¯çµæ´»é›†æˆåˆ°ä»»ä½•Pythonåç«¯
- âœ… ä¸ä¾èµ–æ•°æ®åº“å’Œç®¡ç†å°

**åŠ£åŠ¿:**
- âŒ éœ€è¦è‡ªè¡Œå®ç°LLMé›†æˆ
- âŒ ç¼ºå°‘æ„å›¾è¯†åˆ«å’Œå·¥å…·è°ƒç”¨
- âŒ éœ€è¦è‡ªè¡Œç®¡ç†å¯¹è¯ä¸Šä¸‹æ–‡

### 4.2 æ–¹æ¡ˆB: ä¸­ç­‰åŠŸèƒ½æ¨¡å—

**é€‚ç”¨åœºæ™¯:** éœ€è¦å®Œæ•´çš„è¯­éŸ³äº¤äº’èƒ½åŠ›ï¼ŒåŒ…å«LLMã€æ„å›¾è¯†åˆ«ç­‰

**åœ¨æ–¹æ¡ˆAåŸºç¡€ä¸Šå¢åŠ :**
```
+ llm/                        # LLMæ¨¡å—
+ intent/                     # æ„å›¾è¯†åˆ«
+ memory/                     # å¯¹è¯è®°å¿†
+ handle/                     # æ¶ˆæ¯å¤„ç†å™¨
+ connection.py               # å®Œæ•´çš„è¿æ¥å¤„ç†
```

**æ ¸å¿ƒä¾èµ–å¢åŠ :**
- openai
- requests

**ä¼˜åŠ¿:**
- âœ… åŠŸèƒ½å®Œæ•´ï¼Œå¼€ç®±å³ç”¨
- âœ… æ”¯æŒå¤šè½®å¯¹è¯
- âœ… æ”¯æŒæ„å›¾è¯†åˆ«å’Œå‡½æ•°è°ƒç”¨

**åŠ£åŠ¿:**
- âš ï¸ ä»£ç é‡ä¸­ç­‰ (~5000è¡Œ)
- âš ï¸ ä¾èµ–è¾ƒå¤š

### 4.3 æ–¹æ¡ˆC: å®Œæ•´æœåŠ¡å¤ç”¨

**é€‚ç”¨åœºæ™¯:** æ–°é¡¹ç›®ä¸å°æ™ºåœºæ™¯ç±»ä¼¼ï¼Œæˆ–ä½œä¸ºå¾®æœåŠ¡ç‹¬ç«‹éƒ¨ç½²

**åšæ³•:**
ç›´æ¥éƒ¨ç½²æ•´ä¸ª`xiaozhi-server`ï¼Œé€šè¿‡WebSocketæˆ–HTTPæ¥å£è°ƒç”¨

**ä¼˜åŠ¿:**
- âœ… é›¶å¼€å‘æˆæœ¬
- âœ… åŠŸèƒ½æœ€å®Œæ•´
- âœ… ç»´æŠ¤ç®€å•

**åŠ£åŠ¿:**
- âŒ èµ„æºå ç”¨è¾ƒå¤§
- âŒ é…ç½®å¤æ‚
- âŒ å¯èƒ½åŒ…å«å¾ˆå¤šç”¨ä¸åˆ°çš„åŠŸèƒ½

---

## 5. ç‹¬ç«‹éƒ¨ç½²æ¶æ„è®¾è®¡

### 5.1 æ¶æ„å›¾

```
æ–°é¡¹ç›®åç«¯æ¶æ„:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         æ–°é¡¹ç›®åç«¯ (FastAPI/Django)       â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ä¸šåŠ¡API   â”‚â”€â”€â”€â–¶â”‚  è¯­éŸ³äº¤äº’æ¨¡å—    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                   â”‚           â”‚
â”‚         â”‚                   â–¼           â”‚
â”‚         â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚         â”‚          â”‚   VAD + ASR      â”‚ â”‚
â”‚         â”‚          â”‚   TTS            â”‚ â”‚
â”‚         â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚  LLMæ¥å£   â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚
         â–¼                    â–¼
   APIåç«¯æœåŠ¡          WebSocketå®¢æˆ·ç«¯
  (å¤„ç†ä¸šåŠ¡é€»è¾‘)       (å‰ç«¯/ç¡¬ä»¶è®¾å¤‡)
```

### 5.2 é›†æˆæ–¹å¼

#### æ–¹å¼1: åµŒå…¥å¼é›†æˆ (æ¨è)

å°†è¯­éŸ³äº¤äº’æ¨¡å—ä½œä¸ºPythonåŒ…é›†æˆåˆ°ç°æœ‰åç«¯:

```python
# main.py (FastAPIç¤ºä¾‹)
from fastapi import FastAPI, WebSocket
from voice_module import VoiceHandler, initialize_modules

app = FastAPI()

# åˆå§‹åŒ–è¯­éŸ³æ¨¡å—
voice_config = {...}
modules = initialize_modules(voice_config)
voice_handler = VoiceHandler(
    asr=modules['asr'],
    tts=modules['tts'],
    vad=modules['vad']
)

@app.websocket("/voice")
async def voice_endpoint(websocket: WebSocket):
    await websocket.accept()
    
    while True:
        # æ¥æ”¶éŸ³é¢‘æ•°æ®
        audio_data = await websocket.receive_bytes()
        
        # ASRè¯†åˆ«
        text = await voice_handler.process_audio(audio_data)
        
        if text:
            # è°ƒç”¨ä½ çš„ä¸šåŠ¡API
            response = await your_api_call(text)
            
            # TTSåˆæˆ
            audio = await voice_handler.text_to_speech(response)
            
            # è¿”å›éŸ³é¢‘
            await websocket.send_bytes(audio)
```

#### æ–¹å¼2: ç‹¬ç«‹æœåŠ¡é›†æˆ

å°†è¯­éŸ³æ¨¡å—éƒ¨ç½²ä¸ºç‹¬ç«‹æœåŠ¡ï¼Œé€šè¿‡APIè°ƒç”¨:

```python
# è¯­éŸ³æœåŠ¡ (ç«¯å£8001)
# voice_service.py
from fastapi import FastAPI, UploadFile

app = FastAPI()

@app.post("/asr")
async def asr_endpoint(audio: UploadFile):
    """è¯­éŸ³è¯†åˆ«æ¥å£"""
    audio_data = await audio.read()
    text = await asr_provider.transcribe(audio_data)
    return {"text": text}

@app.post("/tts")
async def tts_endpoint(text: str):
    """è¯­éŸ³åˆæˆæ¥å£"""
    audio = await tts_provider.to_tts(text)
    return audio

# ä¸»ä¸šåŠ¡åç«¯ (ç«¯å£8000)
# main.py
import httpx

async def voice_to_api(audio_data):
    # 1. è°ƒç”¨ASRæœåŠ¡
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8001/asr",
            files={"audio": audio_data}
        )
        text = response.json()["text"]
    
    # 2. æå–å…³é”®ä¿¡æ¯ (ä½ çš„ä¸šåŠ¡é€»è¾‘)
    params = extract_params_from_text(text)
    
    # 3. è°ƒç”¨API
    result = await your_business_api(params)
    
    # 4. è°ƒç”¨TTSæœåŠ¡
    async with httpx.AsyncClient() as client:
        audio_response = await client.post(
            "http://localhost:8001/tts",
            json={"text": result}
        )
        return audio_response.content
```

---

## 6. æŠ€æœ¯å®ç°è·¯çº¿

### 6.1 å¿«é€Ÿå®æ–½è·¯çº¿å›¾

**Phase 1: æ ¸å¿ƒæŠ½å– (1-2å¤©)**
1. å¤åˆ¶æ ¸å¿ƒæ–‡ä»¶åˆ°æ–°æ¨¡å—
   ```bash
   # å¿…éœ€æ–‡ä»¶
   core/providers/asr/base.py
   core/providers/asr/fun_local.py
   core/providers/tts/base.py
   core/providers/tts/edge.py
   core/providers/vad/silero.py
   core/utils/audio_utils.py
   core/utils/opus_encoder_utils.py
   ```

2. ç®€åŒ–é…ç½®ç³»ç»Ÿ
   ```yaml
   # minimal_config.yaml
   asr:
     type: fun_local
     model_dir: ./models/asr
   
   tts:
     type: edge
     voice: zh-CN-XiaoxiaoNeural
   
   vad:
     type: silero
     threshold: 0.5
   ```

3. åˆ›å»ºç®€åŒ–çš„å¤„ç†å™¨
   ```python
   # simple_voice_handler.py
   ```

**Phase 2: é›†æˆæµ‹è¯• (1å¤©)**
1. ç¼–å†™å•å…ƒæµ‹è¯•
2. æµ‹è¯•ASRå‡†ç¡®ç‡
3. æµ‹è¯•TTSéŸ³è´¨
4. æµ‹è¯•ç«¯åˆ°ç«¯æµç¨‹

**Phase 3: ä¸šåŠ¡é›†æˆ (2-3å¤©)**
1. å®ç°å‚æ•°æå–é€»è¾‘
2. å¯¹æ¥ç°æœ‰API
3. é”™è¯¯å¤„ç†å’Œæ—¥å¿—
4. æ€§èƒ½ä¼˜åŒ–

**Phase 4: éƒ¨ç½²ä¸Šçº¿ (1å¤©)**
1. DockeråŒ–
2. é…ç½®ç”Ÿäº§ç¯å¢ƒ
3. ç›‘æ§å‘Šè­¦

### 6.2 å‚æ•°æå–ç¤ºä¾‹

```python
# param_extractor.py
import re
from typing import Dict, Any

class ParamExtractor:
    """ä»è¯­éŸ³è¯†åˆ«æ–‡æœ¬ä¸­æå–APIå‚æ•°"""
    
    def extract_booking_params(self, text: str) -> Dict[str, Any]:
        """
        ç¤ºä¾‹: ä»"æˆ‘æƒ³é¢„è®¢æ˜å¤©ä¸‹åˆ3ç‚¹çš„ä¼šè®®å®¤"æå–å‚æ•°
        """
        params = {}
        
        # æ—¶é—´æå–
        time_patterns = {
            r'æ˜å¤©': lambda: get_tomorrow(),
            r'åå¤©': lambda: get_day_after_tomorrow(),
            r'(\d+)ç‚¹': lambda m: f"{m.group(1)}:00"
        }
        
        for pattern, extractor in time_patterns.items():
            match = re.search(pattern, text)
            if match:
                params['time'] = extractor() if callable(extractor) else extractor(match)
        
        # èµ„æºæå–
        if 'ä¼šè®®å®¤' in text:
            params['resource_type'] = 'meeting_room'
        elif 'è½¦è¾†' in text:
            params['resource_type'] = 'vehicle'
            
        return params
    
    def extract_query_params(self, text: str) -> Dict[str, Any]:
        """
        ç¤ºä¾‹: ä»"æŸ¥è¯¢æœ€è¿‘7å¤©çš„é”€å”®æ•°æ®"æå–å‚æ•°
        """
        params = {}
        
        # æ•°å­—æå–
        num_match = re.search(r'(\d+)å¤©', text)
        if num_match:
            params['days'] = int(num_match.group(1))
        
        # ç±»å‹æå–
        if 'é”€å”®' in text:
            params['type'] = 'sales'
        elif 'åº“å­˜' in text:
            params['type'] = 'inventory'
            
        return params
```

---

## 7. è¿ç§»éƒ¨ç½²æŒ‡å—

### 7.1 ä¾èµ–å®‰è£…

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# æœ€å°ä¾èµ– (æ–¹æ¡ˆA)
pip install websockets==14.2
pip install silero_vad==6.0.0
pip install opuslib_next==1.1.2
pip install numpy==1.26.4
pip install pydub==0.25.1
pip install edge_tts==7.0.0  # å¦‚ä½¿ç”¨EdgeTTS

# å¦‚ä½¿ç”¨æœ¬åœ°ASR
pip install funasr==1.2.3
pip install torch==2.2.2
pip install torchaudio==2.2.2

# å¦‚ä½¿ç”¨APIè°ƒç”¨
pip install httpx==0.27.2
pip install aiohttp==3.12.15
```

### 7.2 Dockeréƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libopus0 \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Pythonä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶ä»£ç 
COPY voice_module/ ./voice_module/
COPY config.yaml .

# ä¸‹è½½æ¨¡å‹ (å¦‚ä½¿ç”¨æœ¬åœ°ASR)
RUN python -c "from funasr import AutoModel; AutoModel(model='paraformer-zh')"

EXPOSE 8000

CMD ["python", "voice_module/voice_server.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  voice-service:
    build: .
    ports:
      - "8001:8000"
    volumes:
      - ./config.yaml:/app/config.yaml
      - ./models:/app/models
    environment:
      - LOG_LEVEL=INFO
    restart: unless-stopped
```

### 7.3 é…ç½®ç¤ºä¾‹

```yaml
# config.yaml - æœ€å°é…ç½®
server:
  host: 0.0.0.0
  port: 8000

# VADé…ç½®
vad:
  type: silero
  threshold: 0.5
  min_speech_duration_ms: 250
  max_speech_duration_s: 30

# ASRé…ç½® - æ–¹æ¡ˆ1: æœ¬åœ°FunASR (æ— éœ€APIå¯†é’¥)
asr:
  type: fun_local
  model: paraformer-zh  # æ”¯æŒä¸­æ–‡
  device: cpu  # æˆ– cuda
  
# ASRé…ç½® - æ–¹æ¡ˆ2: ç«å±±å¼•æ“æµå¼ASR
# asr:
#   type: doubao_stream
#   api_key: "your_api_key"
#   app_id: "your_app_id"

# TTSé…ç½® - æ–¹æ¡ˆ1: EdgeTTS (å®Œå…¨å…è´¹)
tts:
  type: edge
  voice: zh-CN-XiaoxiaoNeural  # æ™“æ™“
  rate: "+0%"
  volume: "+0%"

# TTSé…ç½® - æ–¹æ¡ˆ2: çµçŠ€æµå¼TTS (å…è´¹)
# tts:
#   type: linkerai
#   voice: BV001_streaming
#   speed: 1.0

# éŸ³é¢‘é…ç½®
audio:
  format: opus
  sample_rate: 16000
  channels: 1
  frame_duration: 60

# æ—¥å¿—é…ç½®
logging:
  level: INFO
  file: logs/voice_module.log
```

---

## 8. å»ºè®®ä¸é£é™©è¯„ä¼°

### 8.1 æ¨èæ–¹æ¡ˆ

**æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘å¼ºçƒˆæ¨èé‡‡ç”¨ "æ–¹æ¡ˆA + ç‹¬ç«‹æœåŠ¡é›†æˆ":**

**ç†ç”±:**
1. âœ… **ä½è€¦åˆ:** è¯­éŸ³æ¨¡å—ä¸ä¸šåŠ¡é€»è¾‘åˆ†ç¦»ï¼Œæ˜“äºç»´æŠ¤
2. âœ… **å¯å¤ç”¨:** ä¸€ä¸ªè¯­éŸ³æœåŠ¡å¯ä»¥æœåŠ¡å¤šä¸ªä¸šåŠ¡ç³»ç»Ÿ
3. âœ… **æ˜“æ‰©å±•:** å¯ä»¥éšæ—¶åˆ‡æ¢ASR/TTSæä¾›å•†
4. âœ… **å¿«é€Ÿä¸Šæ‰‹:** æ ¸å¿ƒä»£ç ä¸è¶…è¿‡3000è¡Œ
5. âœ… **æˆæœ¬å¯æ§:** å¯ä»¥é€‰æ‹©å®Œå…¨å…è´¹çš„æ–¹æ¡ˆ (FunASR + EdgeTTS)

### 8.2 æœ€å°éƒ¨ç½²é…ç½®æ¨è

```
æ¨èé…ç½®:
- CPU: 2æ ¸ (å¦‚ä½¿ç”¨API)/ 4æ ¸ (å¦‚ä½¿ç”¨æœ¬åœ°FunASR)
- å†…å­˜: 2GB (å¦‚ä½¿ç”¨API)/ 4GB (å¦‚ä½¿ç”¨æœ¬åœ°FunASR)
- å­˜å‚¨: 10GB (æ¨¡å‹æ–‡ä»¶çº¦2-3GB)
- ç½‘ç»œ: éœ€è¦å¤–ç½‘è®¿é—® (å¦‚ä½¿ç”¨äº‘æœåŠ¡API)

æ€§èƒ½æŒ‡æ ‡:
- ASRå»¶è¿Ÿ: 500-800ms (æœ¬åœ°) / 300-500ms (äº‘API)
- TTSå»¶è¿Ÿ: 200-500ms (EdgeTTS) / 100-300ms (æµå¼TTS)
- å¹¶å‘èƒ½åŠ›: 5-10ä¸ªè¿æ¥ (å–å†³äºç¡¬ä»¶)
```

### 8.3 æŠ€æœ¯é£é™©

| é£é™©ç‚¹ | ä¸¥é‡ç¨‹åº¦ | åº”å¯¹æªæ–½ |
|--------|----------|----------|
| ASRè¯†åˆ«å‡†ç¡®ç‡ | âš ï¸ ä¸­ | ä½¿ç”¨å•†ç”¨API (ç«å±±/é˜¿é‡Œäº‘) æé«˜å‡†ç¡®ç‡ |
| éŸ³é¢‘æ ¼å¼å…¼å®¹ | âš ï¸ ä¸­ | ç»Ÿä¸€ä½¿ç”¨Opusæ ¼å¼ï¼Œå…¼å®¹æ€§å¼º |
| ç½‘ç»œå»¶è¿Ÿ | âš ï¸ ä¸­ | ä¼˜å…ˆä½¿ç”¨æµå¼å¤„ç†é™ä½å»¶è¿Ÿæ„ŸçŸ¥ |
| å¹¶å‘æ€§èƒ½ | ğŸ”´ é«˜ | ä½¿ç”¨å¼‚æ­¥å¤„ç† + é™æµç­–ç•¥ |
| æ¨¡å‹åŠ è½½æ…¢ | âš ï¸ ä¸­ | æå‰é¢„çƒ­æ¨¡å‹ï¼Œä½¿ç”¨æ¨¡å‹ç¼“å­˜ |

### 8.4 å®æ–½å»ºè®®

**å»ºè®®åˆ†ä¸‰æ­¥èµ°:**

**ç¬¬ä¸€æ­¥ (1å‘¨):** å¿«é€ŸéªŒè¯
- æŠ½å–æœ€å°åŠŸèƒ½é›† (ASR + TTS + VAD)
- æ­å»ºDemoç¯å¢ƒ
- éªŒè¯è¯†åˆ«å‡†ç¡®ç‡å’Œå»¶è¿Ÿ
- è¯„ä¼°æ˜¯å¦æ»¡è¶³ä¸šåŠ¡éœ€æ±‚

**ç¬¬äºŒæ­¥ (2å‘¨):** ä¸šåŠ¡é›†æˆ
- å¼€å‘å‚æ•°æå–é€»è¾‘
- å¯¹æ¥ç°æœ‰API
- å®Œå–„é”™è¯¯å¤„ç†
- ç¼–å†™å•å…ƒæµ‹è¯•

**ç¬¬ä¸‰æ­¥ (1å‘¨):** ä¼˜åŒ–ä¸Šçº¿
- æ€§èƒ½è°ƒä¼˜
- éƒ¨ç½²ç”Ÿäº§ç¯å¢ƒ
- ç›‘æ§å‘Šè­¦
- ç¼–å†™æ–‡æ¡£

### 8.5 æˆæœ¬é¢„ä¼°

**æ–¹æ¡ˆå¯¹æ¯”:**

| æ–¹æ¡ˆ | åˆæœŸå¼€å‘ | è¿è¥æˆæœ¬/æœˆ | è¯´æ˜ |
|------|----------|-------------|------|
| æœ¬åœ°FunASR + EdgeTTS | 3-5å¤© | Â¥0 | å®Œå…¨å…è´¹ï¼Œéœ€è¦GPUåŠ é€Ÿ |
| æœ¬åœ°FunASR + å•†ç”¨TTS | 3-5å¤© | Â¥50-200 | TTSæŒ‰é‡è®¡è´¹ |
| äº‘ASR + äº‘TTS | 2-3å¤© | Â¥200-500 | å…¨éƒ¨æŒ‰é‡è®¡è´¹ï¼Œå»¶è¿Ÿæœ€ä½ |
| å¤ç”¨xiaozhi-server | 1å¤© | Â¥0-200 | å¿«é€Ÿä½†å®šåˆ¶æ€§å·® |

---

## 9. å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

### 9.1 æœ€ç®€å®ç° (100è¡Œä»£ç )

```python
# minimal_voice_service.py
import asyncio
import websockets
from funasr import AutoModel
import edge_tts
import io

# åˆå§‹åŒ–ASR
asr_model = AutoModel(model="paraformer-zh")

# åˆå§‹åŒ–TTS
async def text_to_speech(text):
    communicate = edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural")
    audio_data = b""
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data += chunk["data"]
    return audio_data

# WebSocketå¤„ç†
async def handle_client(websocket):
    audio_buffer = []
    
    async for message in websocket:
        if isinstance(message, bytes):
            # éŸ³é¢‘æ•°æ®
            audio_buffer.append(message)
        elif message == "END":
            # è¯­éŸ³ç»“æŸï¼Œè¿›è¡Œè¯†åˆ«
            audio_data = b"".join(audio_buffer)
            
            # ASRè¯†åˆ«
            result = asr_model.generate(audio_data)
            text = result[0]["text"]
            
            # è¿™é‡Œå¯¹æ¥ä½ çš„API
            response = your_api_call(text)
            
            # TTSåˆæˆ
            audio = await text_to_speech(response)
            
            # è¿”å›éŸ³é¢‘
            await websocket.send(audio)
            
            # æ¸…ç©ºç¼“å­˜
            audio_buffer.clear()

# å¯åŠ¨æœåŠ¡
async def main():
    async with websockets.serve(handle_client, "0.0.0.0", 8000):
        print("Voice service started on ws://0.0.0.0:8000")
        await asyncio.Future()

if __name__ == "__main__":
    asyncio.run(main())
```

### 9.2 æµ‹è¯•å®¢æˆ·ç«¯

```python
# test_client.py
import asyncio
import websockets
import wave

async def test_voice_service():
    # è¯»å–æµ‹è¯•éŸ³é¢‘
    with wave.open("test.wav", "rb") as wf:
        audio_data = wf.readframes(wf.getnframes())
    
    # è¿æ¥æœåŠ¡
    async with websockets.connect("ws://localhost:8000") as ws:
        # å‘é€éŸ³é¢‘
        await ws.send(audio_data)
        await ws.send("END")
        
        # æ¥æ”¶ç»“æœ
        response_audio = await ws.recv()
        
        # ä¿å­˜ç»“æœ
        with open("response.wav", "wb") as f:
            f.write(response_audio)
        
        print("è¯­éŸ³å“åº”å·²ä¿å­˜åˆ° response.wav")

asyncio.run(test_voice_service())
```

---

## 10. æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **xiaozhi-esp32-serverçš„è¯­éŸ³äº¤äº’æ¨¡å—è®¾è®¡ä¼˜ç§€**
   - æ¨¡å—åŒ–æ¶æ„ï¼ŒèŒè´£æ¸…æ™°
   - æ”¯æŒå¤šç§ASR/TTSæä¾›å•†
   - æµå¼å¤„ç†é™ä½å»¶è¿Ÿ

2. **å®Œå…¨å¯ä»¥æŠ½å–æœ€å°åŠŸèƒ½é›†**
   - æ ¸å¿ƒä»£ç ä¸è¶…è¿‡3000è¡Œ
   - ä¾èµ–æ¸…æ™°ï¼Œæ˜“äºéƒ¨ç½²
   - å¯ä»¥åªä¿ç•™VAD+ASR+TTS

3. **æ¨èå®æ–½è·¯å¾„**
   - å…ˆæŠ½å–æœ€å°åŠŸèƒ½é›†éªŒè¯
   - é‡‡ç”¨ç‹¬ç«‹æœåŠ¡æ¶æ„
   - ä½¿ç”¨å…è´¹æ–¹æ¡ˆé™ä½æˆæœ¬ (FunASR + EdgeTTS)

4. **å…³é”®æŠ€æœ¯**
   - WebSocketå®ç°å®æ—¶é€šä¿¡
   - VADæ£€æµ‹è¯­éŸ³ç«¯ç‚¹
   - å¼‚æ­¥å¤„ç†æé«˜å¹¶å‘
   - OpuséŸ³é¢‘ç¼–ç é™ä½å¸¦å®½

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³å¯åš:**
   - å…‹éš†xiaozhi-esp32-serverä»“åº“
   - æŒ‰ç…§æœ¬æ–‡æ¡£æŠ½å–æ ¸å¿ƒæ–‡ä»¶
   - æ­å»ºæœ€å°DemoéªŒè¯æ•ˆæœ

2. **éœ€è¦å†³ç­–:**
   - é€‰æ‹©ASRæ–¹æ¡ˆ (æœ¬åœ° vs äº‘API)
   - é€‰æ‹©TTSæ–¹æ¡ˆ (å…è´¹ vs å•†ç”¨)
   - é€‰æ‹©é›†æˆæ–¹å¼ (åµŒå…¥ vs ç‹¬ç«‹æœåŠ¡)

3. **èµ„æºå‡†å¤‡:**
   - ç”³è¯·äº‘æœåŠ¡APIå¯†é’¥ (å¦‚éœ€è¦)
   - å‡†å¤‡æµ‹è¯•éŸ³é¢‘æ•°æ®
   - æ­å»ºå¼€å‘ç¯å¢ƒ

---

## é™„å½•

### A. æ ¸å¿ƒæ–‡ä»¶æ¸…å•

**å¿…é¡»æŠ½å–çš„æ–‡ä»¶ (æ–¹æ¡ˆA - æœ€å°åŠŸèƒ½é›†):**
```
core/providers/asr/base.py
core/providers/asr/fun_local.py
core/providers/tts/base.py
core/providers/tts/edge.py
core/providers/vad/silero.py
core/utils/audio_utils.py
core/utils/opus_encoder_utils.py
```

**å¯é€‰æ–‡ä»¶ (æ–¹æ¡ˆB - å®Œæ•´åŠŸèƒ½):**
```
+ core/connection.py
+ core/handle/receiveAudioHandle.py
+ core/handle/sendAudioHandle.py
+ core/providers/llm/base.py
+ core/providers/intent/function_call.py
+ core/providers/memory/mem_local_short.py
+ core/utils/dialogue.py
+ core/utils/textUtils.py
```

### B. å‚è€ƒèµ„æº

- **é¡¹ç›®æ–‡æ¡£:** https://github.com/xinnan-tech/xiaozhi-esp32-server
- **éƒ¨ç½²æ•™ç¨‹:** docs/Deployment.md
- **æ€§èƒ½æµ‹è¯•:** docs/performance_tester.md
- **FunASRæ–‡æ¡£:** https://github.com/alibaba-damo-academy/FunASR
- **EdgeTTSæ–‡æ¡£:** https://github.com/rany2/edge-tts

---

**æ–‡æ¡£ç‰ˆæœ¬:** v1.0  
**æœ€åæ›´æ–°:** 2025-09-30  
**ä½œè€…:** AIæŠ€æœ¯é¡¾é—®
